---
title: "Diabetes dementia analysis simulation results"
author: "Andrew Mertens"
#output: html_document
output: github_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)


rm(list=ls())
gc()
shh <-try(setwd("C:/Users/andre/Documents/jici/registry_simulations/"),silent = TRUE)
shh <-try(setwd("~/research/Methods/registry_simulations/"),silent = TRUE)
library(targets)
library(tarchetypes)
library(parallel)

lapply(c("fst","lava","ltmle","data.table","tidyverse","glmnet","Matrix","matrixStats","speedglm","parallel","caret","foreach","clustermq"), FUN = function(X) {
  do.call("require", list(X)) 
})

nn=lapply(list.files("./reals/", full.names = TRUE, recursive=TRUE), source)
nn=lapply(list.files("./Ltmle/Augmentation/", full.names = TRUE, recursive=TRUE), source)

truth<- readRDS(file=paste0(here::here(),"/data/sim_results/truth.rds"))



```

## Simulation setup


-   N: 100,000

-   Iterations: 500

-   True $Y_{\bar{A}=1}$: `R truth[10,2]`

-   True RD: `R truth[10,4]`

-   True RR: `R truth[10,3]`

## Simulation results

```{r,  echo=F}

ic_res <- read.csv(file=paste0(here::here(),"/data/sim_perf_500reps.csv"))
colnames(ic_res)
ic_res <- ic_res %>% subset(., select = -c(N_reps))
ic_res <- ic_res %>% rename(Algorithm=estimator,
                            `Y_{A=1} bias`=abs_bias_Ya1,
                            `Y_{A=1} variance`=mean_variance_Ya1,
                            `Y_{A=1} bias SE ratio`=bias_se_ratio_Ya1,
                            `RD bias`=abs_bias_RD,
                            `RD variance`=mean_variance_RD,
                            `RD bias SE ratio`=bias_se_ratio_RD,
                            `RR log-transformed bias`=abs_log_bias_RR,
                            `RR variance`=mean_variance_RR,
                            `RR bias SE ratio`=bias_se_ratio_RR,
                            `Y_{A=1} oracle 95% coverage`=O_coverage_Ya1,
                            `RD oracle 95% coverage`=O_coverage_RD,
                            `RR oracle 95% coverage`=O_coverage_RR
                            )

#   "estimator_variance_Ya1" "mean_variance_Ya1"          
#  [9] "coverage_Ya1"           ""                     "estimator_variance_RD"              
# [17] "abs_log_bias_RR"        "estimator_variance_RR"  "mean_variance_RR"             
# [21] "coverage_RR"            ""  

```

#### Comparison of IPTW and TMLE estimators

Both from Lasso models with $\lambda$ selected at the minimum cross-validated SE

```{r,  echo=F}

iptw_res <- ic_res %>% filter(Algorithm=="glmnet") %>%
  subset(., select = c(Estimator, Algorithm,
                            `Y_{A=1} bias`,
                            `Y_{A=1} variance`, `Y_{A=1} bias SE ratio`, `Y_{A=1} oracle 95% coverage`,
                            `RD bias`,`RD variance`,`RD bias SE ratio`, `RD oracle 95% coverage`,
                            `RR log-transformed bias`,`RR variance`,`RR bias SE ratio`, `RR oracle 95% coverage`))


knitr::kable(iptw_res, digits =5)

```

Result: TMLE performs better

#### Comparison of algorithms

All penalized regressions with $\lambda$ selected at the minimum cross-validated SE, truncation of $g$ at < 0.01, and using all prior L nodes in $g$ and $Q$ estimation.

RF= random forest


```{r,  echo=F}

algo_res <- ic_res %>% filter(Estimator=="tmle") %>%
  filter(!grepl("_untruncated", Algorithm), !grepl("_markov", Algorithm), !grepl("_undersmooth", Algorithm)) %>%
  subset(., select = c(Estimator, Algorithm,
                            `Y_{A=1} bias`,
                            `Y_{A=1} variance`, `Y_{A=1} bias SE ratio`, `Y_{A=1} oracle 95% coverage`,
                            `RD bias`,`RD variance`,`RD bias SE ratio`, `RD oracle 95% coverage`,
                            `RR log-transformed bias`,`RR variance`,`RR bias SE ratio`, `RR oracle 95% coverage`))

knitr::kable(algo_res, digits =5)

```

Result: Ridge performs best

#### Comparison of penalized regression setup

Define different options

All from Lasso models 

 = $\lambda$ selected at the minimum cross-validated SE



 penalized regressions with $\lambda$ selected at the minimum cross-validated SE, truncation of $g$ at < 0.01, and using all prior L nodes in $g$ and $Q$ estimation.
 
```{r,  echo=F}

sim_res <- ic_res %>% filter(grepl("ridge", Algorithm)) %>%
  #filter(!grepl("_untruncated", Algorithm), !grepl("_markov", Algorithm), !grepl("_undersmooth", Algorithm)) %>%
  subset(., select = c(Estimator, Algorithm,
                            `Y_{A=1} bias`,
                            `Y_{A=1} variance`, `Y_{A=1} bias SE ratio`, `Y_{A=1} oracle 95% coverage`,
                            `RD bias`,`RD variance`,`RD bias SE ratio`, `RD oracle 95% coverage`,
                            `RR log-transformed bias`,`RR variance`,`RR bias SE ratio`, `RR oracle 95% coverage`))

knitr::kable(sim_res, digits =5)

```


Result: Undersmoothed Ridge with default truncation and markov process for L works best

## Comparison of IC and Bootstrap based coverages

```{r,  echo=F}

boot1 <- readRDS(file=paste0(here::here(),"/data/sim_results/res_ridge_undersmooth_markov_boot1.RDS")) %>% mutate(boot_run=1)
boot2 <- readRDS(file=paste0(here::here(),"/data/sim_results/res_ridge_undersmooth_markov_boot2.RDS")) %>% mutate(boot_run=2)
boot3 <- readRDS(file=paste0(here::here(),"/data/sim_results/res_ridge_undersmooth_markov_boot3.RDS")) %>% mutate(boot_run=3)
boot4 <- readRDS(file=paste0(here::here(),"/data/sim_results/res_ridge_undersmooth_markov_boot4.RDS")) %>% mutate(boot_run=4)
boot5 <- readRDS(file=paste0(here::here(),"/data/sim_results/res_ridge_undersmooth_markov_boot5.RDS")) %>% mutate(boot_run=5)
boot_res <- bind_rows(boot1, boot2, boot3, boot4, boot5)
bootCIs <- boot_res %>% group_by(Target_parameter, sim_iter, boot_run) %>%
  summarise(
    boot.CI1=quantile(estimate,.025),
    boot.CI2=quantile(estimate,.975)
  )

boot_res_A1=mean(bootCIs$boot.CI1[bootCIs$Target_parameter=="Risk(A=1)"] < truth$meanYa1[10] & bootCIs$boot.CI2[bootCIs$Target_parameter=="Risk(A=1)"] > truth$meanYa1[10] )*100
boot_res_RD=mean(bootCIs$boot.CI1[bootCIs$Target_parameter=="ATE"] < truth$meanRD[10] & bootCIs$boot.CI2[bootCIs$Target_parameter=="ATE"] > truth$meanRD[10] )*100
boot_res_RR=mean(bootCIs$boot.CI1[bootCIs$Target_parameter=="RelativeRisk"] < truth$meanRR[10] & bootCIs$boot.CI2[bootCIs$Target_parameter=="RelativeRisk"] > truth$meanRR[10] )*100

ic_res_comp=ic_res %>% filter(Algorithm=="ridge_undersmooth_markov", Estimator=="tmle")

boot_res_tab <- data.frame(`Variance estimator`=c("Influence curve","Bootstrap"),
                      `Y_{A=1} Coverage`=c(ic_res_comp$coverage_Ya1, boot_res_A1),
                      `RD Coverage`=c(ic_res_comp$coverage_RD, boot_res_RD),
                      `RR Coverage`=c(ic_res_comp$coverage_RR, boot_res_RR))
knitr::kable(boot_res_tab)

```

Results: Bootstrap has better coverage for RR and especially RD, but slightly worse that for the mean of  $Y_{A=1}$

## Boxplots

- Make two boxplots of bootstrap vs IC


## Updated needed in the registry analysis

Because of updated in (I think) TMLE_for_breakfast, there are now D nodes for competing events, and when we run the old code we get the error:

Current error: "Cannot both specify determistic.Q.nodes and Dnodes"

I think I just need to update both the run_tmle() and prepare_tmle() functions to be able to pass a Dnodes=NULL argument through the functions, because right now Dnodes are automatically set to be any variable with "dead" within the name. But do I do that on Statistics Denmark or make the changes on Ltmle_for_breakfast, and if the latter, how do I export the update so it's on Statistics Denmark?

## Estimator to run:

undersmoothed ridge with markov=TRUE

```{r, eval=FALSE, echo=TRUE}

v=run_ltmle(OUT="dementia",k=10,test=FALSE,treatment_regimens=treatment_regimens,outcomes=outcomes,baseline_covariates=baseline_covariates,timevar_covariates=timevar_covariates,det.Q.function=det.Q.function,abar="try",
            SL.library="glmnet",SL.cvControl=list(selector="undersmooth",alpha=1), 
            Markov=Markov_vars)

```

With Markov_vars being all time-varying L nodes

## Updated needed in the registry analysis

Bochra was helping us rerun the analysis on the Danish registry based on the updated simulation results with 500 iterations (undersmoothed ridge won). Because of updated in (I think) TMLE_for_breakfast, there are now D nodes for competing events, and when we run the old code we get the error:

"Cannot both specify determistic.Q.nodes and Dnodes"

I think I just need to update both the run_tmle() and prepare_tmle() functions to be able to pass a Dnodes=NULL argument through the functions, because right now Dnodes are automatically set to be any variable with "dead" within the name. But do I do that on Statistics Denmark or make the changes on Ltmle_for_breakfast, and if the latter, how do I export the update so it's on Statistics Denmark?
